{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_8QsrFMqiu0"
      },
      "source": [
        "# Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_tHfUsEoLJi",
        "outputId": "7a4d6bf1-8509-4d96-e36b-c4d464f9e5be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-lightning==2.1.0 in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.0) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.0) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.0) (6.0.2)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.1.0) (2024.10.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.0) (1.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.0) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.0) (0.11.9)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.1.0) (3.11.11)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning==2.1.0) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lightning==2.1.0) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.12.0->pytorch-lightning==2.1.0) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.12.0->pytorch-lightning==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.0) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.0) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.12.0->pytorch-lightning==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.0) (3.10)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core) (24.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.2)\n",
            "Requirement already satisfied: torcheval in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torcheval) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries and packages.\n",
        "\n",
        "! pip install pytorch-lightning==2.1.0\n",
        "! pip install hydra-core --upgrade\n",
        "! pip install torcheval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nlijo8Akmc7o"
      },
      "source": [
        "# Download data and model CT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt7U8GuZWV18",
        "outputId": "0cd406bd-aeaa-4038-903c-e9a9b65b096a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1QE-X4z1xT2_xDszWH47F_5bl4jCaqxVm\n",
            "From (redirected): https://drive.google.com/uc?id=1QE-X4z1xT2_xDszWH47F_5bl4jCaqxVm&confirm=t&uuid=5e456d70-095c-4226-897f-14dd49ef4952\n",
            "To: /content/data.zip\n",
            "100% 95.8M/95.8M [00:01<00:00, 59.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1udpraFyj0DMWsxFuA5qlXEuKTncmVrfn\n",
        "!unzip -q data.zip\n",
        "!rm data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1VCEPncnY1p"
      },
      "source": [
        "# Model and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PS9EyoKPC7kY"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "\n",
        "class SegmentationImageFolder(Dataset):\n",
        "    def __init__(self, dataset_path, transform):\n",
        "        self.image_dir = dataset_path + \"/data\"\n",
        "        self.mask_dir = dataset_path + \"/mask\"\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(self.image_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.images[idx])\n",
        "        image = Image.open(image_path).convert(\"L\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "        return self.transform(image), self.transform(mask)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ljfSbkWV81R1"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.transforms import Resize, ToTensor\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "\n",
        "class CTDataset(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        batch_size,\n",
        "        data_dir=\"/content/data/CT/png\",\n",
        "        train_dir=\"/train_dir\",\n",
        "        test_dir=\"/test_dir\",\n",
        "        num_classes=1,\n",
        "        padding=True,\n",
        "        image_small=True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.data_dir = data_dir\n",
        "        self.train_dataset_path = data_dir + train_dir\n",
        "        self.test_dataset_path = data_dir + test_dir\n",
        "        self.num_classes = num_classes\n",
        "        if image_small:\n",
        "            self.image_size = (256, 256)\n",
        "        else:\n",
        "            self.image_size = (512, 512)\n",
        "        if padding:\n",
        "            self.transform = transforms.Compose(\n",
        "                [transforms.Pad((61, 61, 62, 62)), Resize(self.image_size), ToTensor()]\n",
        "            )  # padding standardowych zdjęć 389x389 do 512x512\n",
        "        else:\n",
        "            self.transform_resize = transforms.Compose(\n",
        "                [Resize(self.image_size), ToTensor()]\n",
        "            )\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            dataset = SegmentationImageFolder(\n",
        "                self.train_dataset_path, transform=self.transform\n",
        "            )\n",
        "            train_dataset_size = int(len(dataset) * 0.8)\n",
        "            self.train_dataset, self.val_dataset = random_split(\n",
        "                dataset, [train_dataset_size, len(dataset) - train_dataset_size]\n",
        "            )\n",
        "        if stage == \"test\" or stage is None:\n",
        "            self.test_dataset = SegmentationImageFolder(\n",
        "                self.test_dataset_path, transform=self.transform\n",
        "            )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g1aEDXxGbtJV"
      },
      "outputs": [],
      "source": [
        "# Unet modules\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Klasa na podstawie kodu z https://github.com/uygarkurt/UNet-PyTorch\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv_op = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv_op(x)\n",
        "\n",
        "\n",
        "# Klasa na podstawie kodu z https://github.com/uygarkurt/UNet-PyTorch\n",
        "class DownSample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        down = self.conv(x)\n",
        "        p = self.pool(down)\n",
        "\n",
        "        return down, p\n",
        "\n",
        "\n",
        "# Klasa na podstawie kodu z https://github.com/uygarkurt/UNet-PyTorch\n",
        "class UpSample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(\n",
        "            in_channels, in_channels // 2, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        x = torch.cat([x1, x2], 1)\n",
        "        return self.conv(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FFUMf9gXDBke"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Kalasa bazująca na teorii przedstawionej w: https://www.youtube.com/watch?v=KOF38xAvo8I&t=574s\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, in_channels_g, in_channels_x, intermediate_channels):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.W_g = nn.Conv2d(\n",
        "            in_channels_g,\n",
        "            intermediate_channels,\n",
        "            kernel_size=1,\n",
        "            stride=(1, 1),\n",
        "            padding=0,\n",
        "            bias=True,\n",
        "        )\n",
        "        self.W_x = nn.Conv2d(\n",
        "            in_channels_x,\n",
        "            intermediate_channels,\n",
        "            kernel_size=1,\n",
        "            stride=(2, 2),\n",
        "            padding=0,\n",
        "            bias=True,\n",
        "        )\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.psi = nn.Conv2d(\n",
        "            intermediate_channels, 1, kernel_size=1, stride=(1, 1), padding=0, bias=True\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        combined = g1 + x1\n",
        "        combined = self.relu(combined)\n",
        "        psi = self.sigmoid(self.psi(combined))\n",
        "        psi = self.upsample(psi)\n",
        "        out = x * psi\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6rOGjMfXBuKI"
      },
      "outputs": [],
      "source": [
        "# Unet structure witch attention\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Klasa częściowo na podstawie kodu z https://github.com/uygarkurt/UNet-PyTorch\n",
        "class UNetWithAttention(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.down_convolution_1 = DownSample(in_channels, 64)\n",
        "        self.down_convolution_2 = DownSample(64, 128)\n",
        "        self.down_convolution_3 = DownSample(128, 256)\n",
        "        self.down_convolution_4 = DownSample(256, 512)\n",
        "\n",
        "        self.bottle_neck = DoubleConv(512, 1024)\n",
        "\n",
        "        self.up_convolution_1 = UpSample(1024, 512)\n",
        "        self.up_convolution_2 = UpSample(512, 256)\n",
        "        self.up_convolution_3 = UpSample(256, 128)\n",
        "        self.up_convolution_4 = UpSample(128, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1)\n",
        "\n",
        "        self.attention_1 = SpatialAttention(1024, 512, 1024)\n",
        "        self.attention_2 = SpatialAttention(512, 256, 512)\n",
        "        self.attention_3 = SpatialAttention(256, 128, 256)\n",
        "        self.attention_4 = SpatialAttention(128, 64, 128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        down_1, p1 = self.down_convolution_1(x)\n",
        "        down_2, p2 = self.down_convolution_2(p1)\n",
        "        down_3, p3 = self.down_convolution_3(p2)\n",
        "        down_4, p4 = self.down_convolution_4(p3)\n",
        "\n",
        "        b = self.bottle_neck(p4)\n",
        "\n",
        "        up_1 = self.up_convolution_1(b, self.attention_1(b, down_4))\n",
        "        up_2 = self.up_convolution_2(up_1, self.attention_2(up_1, down_3))\n",
        "        up_3 = self.up_convolution_3(up_2, self.attention_3(up_2, down_2))\n",
        "        up_4 = self.up_convolution_4(up_3, self.attention_4(up_3, down_1))\n",
        "\n",
        "        out = self.out(up_4)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bu6-hXeDb1fE"
      },
      "outputs": [],
      "source": [
        "# Unet structure\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from unet_parts import DoubleConv, DownSample, UpSample\n",
        "\n",
        "\n",
        "# Klasa na podstawie kodu z https://github.com/uygarkurt/UNet-PyTorch\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.down_convolution_1 = DownSample(in_channels, 64)\n",
        "        self.down_convolution_2 = DownSample(64, 128)\n",
        "        self.down_convolution_3 = DownSample(128, 256)\n",
        "        self.down_convolution_4 = DownSample(256, 512)\n",
        "\n",
        "        self.bottle_neck = DoubleConv(512, 1024)\n",
        "\n",
        "        self.up_convolution_1 = UpSample(1024, 512)\n",
        "        self.up_convolution_2 = UpSample(512, 256)\n",
        "        self.up_convolution_3 = UpSample(256, 128)\n",
        "        self.up_convolution_4 = UpSample(128, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        down_1, p1 = self.down_convolution_1(x)\n",
        "        down_2, p2 = self.down_convolution_2(p1)\n",
        "        down_3, p3 = self.down_convolution_3(p2)\n",
        "        down_4, p4 = self.down_convolution_4(p3)\n",
        "\n",
        "        b = self.bottle_neck(p4)\n",
        "\n",
        "        up_1 = self.up_convolution_1(b, down_4)\n",
        "        up_2 = self.up_convolution_2(up_1, down_3)\n",
        "        up_3 = self.up_convolution_3(up_2, down_2)\n",
        "        up_4 = self.up_convolution_4(up_3, down_1)\n",
        "\n",
        "        out = self.out(up_4)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tJfw5DxGrwKf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torcheval.metrics.functional import binary_f1_score\n",
        "from rich.console import Console\n",
        "\n",
        "console = Console()\n",
        "\n",
        "\n",
        "class UNetModel(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        learning_rate=1e-3,\n",
        "        scheduler_step_size=8,\n",
        "        scheduler_gamma=0.5,\n",
        "        pos_weight=2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.out_channels = out_channels\n",
        "        self.scheduler_step_size = scheduler_step_size\n",
        "        self.scheduler_gamma = scheduler_gamma\n",
        "        self.pos_weight = pos_weight\n",
        "\n",
        "        self.model = UNetWithAttention(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def compute_loss(self, x, y):\n",
        "        pos_weight = torch.tensor([self.pos_weight]).cuda()\n",
        "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "        return criterion(x, y)\n",
        "\n",
        "    def common_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        outputs = self(x)\n",
        "        loss = self.compute_loss(outputs, y)\n",
        "        return loss, outputs, y\n",
        "\n",
        "    def common_test_valid_step(self, batch, batch_idx):\n",
        "        loss, outputs, y = self.common_step(batch, batch_idx)\n",
        "        acc = binary_f1_score(outputs.view(-1), y.view(-1), threshold=0.5)\n",
        "        return loss, acc\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, acc = self.common_test_valid_step(batch, batch_idx)\n",
        "        self.log(\n",
        "            \"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True, logger=True\n",
        "        )\n",
        "        self.log(\n",
        "            \"train_acc\", acc, prog_bar=True, on_step=True, on_epoch=True, logger=True\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, acc = self.common_test_valid_step(batch, batch_idx)\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", acc, prog_bar=True)\n",
        "        console.print(\n",
        "            f\"Validation [bold cyan]Loss (batch {batch_idx}): {loss:.4f}[bold cyan]\"\n",
        "        )\n",
        "        console.print(\n",
        "            f\"Validation [bold green]Accuracy (batch {batch_idx}): {acc:.4f}[/bold green]\"\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss, acc = self.common_test_valid_step(batch, batch_idx)\n",
        "        self.log(\"test_loss\", loss, prog_bar=True)\n",
        "        self.log(\"test_acc\", acc, prog_bar=True)\n",
        "        console.print(\n",
        "            f\"Test [bold cyan]Loss (batch {batch_idx}): {loss:.4f}[bold cyan]\"\n",
        "        )\n",
        "        console.print(\n",
        "            f\"Test [bold green]Accuracy (batch {batch_idx}): {acc:.4f}[/bold green]\"\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        lr_scheduler = optim.lr_scheduler.StepLR(\n",
        "            optimizer, step_size=self.scheduler_step_size, gamma=self.scheduler_gamma\n",
        "        )\n",
        "        return [optimizer], [lr_scheduler]\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzv4MIrfnjN3"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "11zyF7dNoQf5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "# czyszczenie pamięci gpu\n",
        "\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w0l_uge7pypR"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    dm = CT_dataset(batch_size=16)\n",
        "    dm.setup()\n",
        "\n",
        "    model = UNetModel(1, dm.num_classes, learning_rate=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrZDKHBr07Ax",
        "outputId": "6f73a40c-15c8-406a-d695-52256a9738fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login --relogin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "-bv-aq23zwXD",
        "outputId": "3d8b1a9d-6ef3-40ca-87fd-2511d0442eb8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlukasstan\u001b[0m (\u001b[33mlukasstan-warsaw-university-of-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250117_200324-trkk2yps</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lukasstan-warsaw-university-of-technology/ct_model/runs/trkk2yps' target=\"_blank\">ancient-cloud-2</a></strong> to <a href='https://wandb.ai/lukasstan-warsaw-university-of-technology/ct_model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/lukasstan-warsaw-university-of-technology/ct_model' target=\"_blank\">https://wandb.ai/lukasstan-warsaw-university-of-technology/ct_model</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/lukasstan-warsaw-university-of-technology/ct_model/runs/trkk2yps' target=\"_blank\">https://wandb.ai/lukasstan-warsaw-university-of-technology/ct_model/runs/trkk2yps</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import wandb\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "wandb.init(project=\"ct_model\")\n",
        "wandb_logger = WandbLogger()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DcUE8Thdz0Dx"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "tensorboard_logger = TensorBoardLogger(\"lightning_logs\", name=\"ct_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599,
          "referenced_widgets": [
            "ecc73a832cba4b23b81f2f669e3fa272",
            "87c16aafebe74c09bdca2e9ea2f66c36",
            "f5e29e131ecb4ca899c595193b9b3180",
            "1d48c03b2e474ceb9068203b6852022d",
            "36519b81805d47f0b35b01b5b1d2a407",
            "5b1b100f10644e289b643fec9a3a0b03",
            "e768c7bd58f84d619aeeff042552ee12",
            "f91a13558a334d3298f574fea7fa5c2c",
            "9b2287485eed4ed8b29e07b3023ffbb7",
            "dc754b5e1e5e4767aefdd2afd123e766",
            "2db5b97436994b6b806796e4ecbc63e3",
            "58caaf8f8a784e6b8f587455054db5bb",
            "37565896e8074c69ab23afa4fb81845e",
            "7e7ce3c3bed3417eb9c96f34bb468b62",
            "f7cf2efdc9d348ffbba7804d31b75b26",
            "dd9852158e504dfdbc29767e753917dd",
            "f0985bd419d84f648751889b839a75e3",
            "48c71a7eef95462b8be0b3e456b6032a",
            "311e72824c0e4b098a188faa5c532425",
            "4621c78a91e7419e803e818cc795d976",
            "688fd089cc0647c9aafe64f5422ac0ae",
            "6cb5a646ce81417a82557c5ac10b5473"
          ]
        },
        "id": "9GYsD1qt2Vy5",
        "outputId": "cb6a844d-c3da-47ca-a8fe-c1fc512bb913"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightning_fabric/connector.py:565: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/plugins/precision/amp.py:54: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/parse_url.py:48: UserWarning: You specified a Google Drive link that is not the correct link to download a file. You might want to try `--fuzzy` option or the following url: https://drive.google.com/uc?id=None\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/1FWGQi6W8d7hWWoMkykhbqY_GUFKlltWp\n",
            "To: /content\n",
            "1.65kB [00:00, 1.41MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type              | Params\n",
            "--------------------------------------------\n",
            "0 | model | UNetWithAttention | 33.1 M\n",
            "--------------------------------------------\n",
            "33.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "33.1 M    Total params\n",
            "132.501   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecc73a832cba4b23b81f2f669e3fa272",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validation <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Loss (batch </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">): </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6949</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Validation \u001b[1;36mLoss \u001b[0m\u001b[1;36m(\u001b[0m\u001b[1;36mbatch \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m)\u001b[0m\u001b[1;36m: \u001b[0m\u001b[1;36m0.6949\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validation <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Accuracy (batch </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">): </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.0000</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Validation \u001b[1;32mAccuracy \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mbatch \u001b[0m\u001b[1;32m0\u001b[0m\u001b[1;32m)\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m0.0000\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validation <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Loss (batch </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">): </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6944</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Validation \u001b[1;36mLoss \u001b[0m\u001b[1;36m(\u001b[0m\u001b[1;36mbatch \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;36m)\u001b[0m\u001b[1;36m: \u001b[0m\u001b[1;36m0.6944\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validation <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Accuracy (batch </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">): </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.0000</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Validation \u001b[1;32mAccuracy \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mbatch \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m)\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m0.0000\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58caaf8f8a784e6b8f587455054db5bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
          ]
        }
      ],
      "source": [
        "trainer = pl.Trainer(\n",
        "    max_epochs=20,\n",
        "    check_val_every_n_epoch=2,\n",
        "    log_every_n_steps=20,\n",
        "    logger=[wandb_logger, tensorboard_logger],\n",
        "    accelerator=\"gpu\",\n",
        "    precision=\"16\"\n",
        ")\n",
        "\n",
        "trainer.fit(model=model, datamodule=dm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bo7gm8YPh0gW"
      },
      "outputs": [],
      "source": [
        "model_save_path = \"/content/unet.pth\"\n",
        "torch.save(model, model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "auxlLTX84hHY"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/lightning_logs/ --host=127.0.0.1 --port=6006 --load_fast=false"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXwGH1IY4hlr"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.serve_kernel_port_as_window(6006, path=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aahC6H22CFSB"
      },
      "source": [
        "# Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3broGbXCJgq"
      },
      "outputs": [],
      "source": [
        "import torch.nn.utils.prune as prune\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def apply_pruning(model, amount=0.2):\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            prune.l1_unstructured(module, name=\"weight\", amount=amount)\n",
        "            # Opcjonalnie usuń maskę po przycięciu\n",
        "            prune.remove(module, \"weight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORvpkaCaCLnQ"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_Tr2oC2CNIq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_weight_distribution(model, title):\n",
        "\n",
        "    weights = torch.tensor([], device=\"cuda\")\n",
        "\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            module_weights = module.weight.to(\"cuda\").flatten()\n",
        "            weights = torch.cat((weights, module_weights))\n",
        "\n",
        "    weights_cpu = weights.detach().cpu().numpy()\n",
        "\n",
        "    plt.hist(weights_cpu, bins=50)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Wartość wagi\")\n",
        "    plt.ylabel(\"Liczba wag\")\n",
        "    plt.xlim(-0.1, 0.1)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD8yt9JeCO1J"
      },
      "outputs": [],
      "source": [
        "def count_zero_weights(model):\n",
        "    zero_weights = 0\n",
        "    total_weights = 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        if hasattr(module, \"weight\") and isinstance(module.weight, torch.Tensor):\n",
        "            zero_weights += torch.sum(module.weight == 0).item()\n",
        "            total_weights += module.weight.numel()\n",
        "\n",
        "    zero_percentage = (zero_weights / total_weights) * 100 if total_weights > 0 else 0\n",
        "    return zero_weights, total_weights, zero_percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXVO5O5TCQix"
      },
      "outputs": [],
      "source": [
        "dm = CT_dataset(batch_size=8)\n",
        "dm.setup()\n",
        "model = UNetModel(1, dm.num_classes, learning_rate=1e-3)\n",
        "\n",
        "model = torch.load(\"unet.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaooxkvtCRq6"
      },
      "outputs": [],
      "source": [
        "# Przed pruningiem\n",
        "print(\"Liczba parametrów przed pruningiem:\", count_parameters(model))\n",
        "plot_weight_distribution(model, \"Rozkład wag przed pruningiem\")\n",
        "zero_weights, total_weights, zero_percentage = count_zero_weights(model)\n",
        "print(f\"Liczba wag równych zero: {zero_weights}\")\n",
        "print(f\"Całkowita liczba wag: {total_weights}\")\n",
        "print(f\"Procent wag równych zero: {zero_percentage:.2f}%\")\n",
        "\n",
        "# Po pruningu\n",
        "apply_pruning(model, amount=0.2)  # Zastosowanie pruning\n",
        "print(\"Liczba parametrów po pruningu:\", count_parameters(model))\n",
        "plot_weight_distribution(model, \"Rozkład wag po pruningu\")\n",
        "zero_weights, total_weights, zero_percentage = count_zero_weights(model)\n",
        "print(f\"Liczba wag równych zero: {zero_weights}\")\n",
        "print(f\"Całkowita liczba wag: {total_weights}\")\n",
        "print(f\"Procent wag równych zero: {zero_percentage:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El90H8bDCUDr"
      },
      "outputs": [],
      "source": [
        "model_save_path = \"/content/unet.pth\"\n",
        "torch.save(model, model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb-9bZEXnl5z"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yre78Kqo_NON"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "# czyszczenie pamięci gpu\n",
        "\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psndmkc7IHrh"
      },
      "outputs": [],
      "source": [
        "dm = CT_dataset(batch_size=8)\n",
        "dm.setup()\n",
        "model = UNetModel(1, dm.num_classes, learning_rate=1e-3)\n",
        "\n",
        "model = torch.load(\"unet.pth\")\n",
        "\n",
        "\n",
        "logger = TensorBoardLogger(\"lightning_logs\", name=\"ct_model\")\n",
        "trainer = pl.Trainer(logger=logger)\n",
        "\n",
        "trainer.test(model=model, datamodule=dm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBnYl1OYY2Fo"
      },
      "outputs": [],
      "source": [
        "# Results presentation (inference)\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# from carvana_dataset import CarvanaDataset\n",
        "# from unet import UNet\n",
        "\n",
        "\n",
        "def pred_show_image_grid(data_path, model_pth, device):\n",
        "    model = torch.load(model_pth)\n",
        "    model = model.to(device)\n",
        "    image_dataset = CT_dataset(8)\n",
        "    image_dataset.setup()\n",
        "\n",
        "    images = [[], [], []]\n",
        "\n",
        "    for i, (image, mask) in enumerate(image_dataset.test_dataloader()):\n",
        "        image = image.to(device)\n",
        "        mask = mask.to(device)\n",
        "        images[0].append(image)\n",
        "        images[1].append(mask)\n",
        "        loss, outputs, y = model.common_step((image, mask), i)\n",
        "        images[2].append(outputs)\n",
        "        break\n",
        "\n",
        "    flattened_images = []\n",
        "\n",
        "    for image_type in images:\n",
        "        for image in image_type[0]:\n",
        "            flattened_images.append(image)\n",
        "\n",
        "    fig, axes = plt.subplots(3, 8, figsize=(16, 6))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < len(flattened_images):\n",
        "            tensor_image = flattened_images[i]\n",
        "\n",
        "            if isinstance(tensor_image, torch.Tensor):\n",
        "                tensor_image = tensor_image.cpu().detach().numpy()\n",
        "\n",
        "            if i > 15:\n",
        "                tensor_image = np.where(tensor_image < 0.5, 0.0, 1.0)\n",
        "\n",
        "            ax.imshow(tensor_image[0], cmap=\"gray\")\n",
        "            ax.axis(\"off\")\n",
        "        else:\n",
        "            ax.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    SINGLE_IMG_PATH = \"/content/data_ct/manual_test/226.png\"\n",
        "    DATA_PATH = \"/content/data_ct\"\n",
        "    MODEL_PATH = \"/content/unet.pth\"\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    pred_show_image_grid(DATA_PATH, MODEL_PATH, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d48c03b2e474ceb9068203b6852022d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc754b5e1e5e4767aefdd2afd123e766",
            "placeholder": "​",
            "style": "IPY_MODEL_2db5b97436994b6b806796e4ecbc63e3",
            "value": " 2/2 [00:01&lt;00:00,  1.14it/s]"
          }
        },
        "2db5b97436994b6b806796e4ecbc63e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "311e72824c0e4b098a188faa5c532425": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36519b81805d47f0b35b01b5b1d2a407": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "37565896e8074c69ab23afa4fb81845e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0985bd419d84f648751889b839a75e3",
            "placeholder": "​",
            "style": "IPY_MODEL_48c71a7eef95462b8be0b3e456b6032a",
            "value": "Epoch 1:  47%"
          }
        },
        "4621c78a91e7419e803e818cc795d976": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48c71a7eef95462b8be0b3e456b6032a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58caaf8f8a784e6b8f587455054db5bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37565896e8074c69ab23afa4fb81845e",
              "IPY_MODEL_7e7ce3c3bed3417eb9c96f34bb468b62",
              "IPY_MODEL_f7cf2efdc9d348ffbba7804d31b75b26"
            ],
            "layout": "IPY_MODEL_dd9852158e504dfdbc29767e753917dd"
          }
        },
        "5b1b100f10644e289b643fec9a3a0b03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "688fd089cc0647c9aafe64f5422ac0ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cb5a646ce81417a82557c5ac10b5473": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e7ce3c3bed3417eb9c96f34bb468b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_311e72824c0e4b098a188faa5c532425",
            "max": 85,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4621c78a91e7419e803e818cc795d976",
            "value": 40
          }
        },
        "87c16aafebe74c09bdca2e9ea2f66c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b1b100f10644e289b643fec9a3a0b03",
            "placeholder": "​",
            "style": "IPY_MODEL_e768c7bd58f84d619aeeff042552ee12",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "9b2287485eed4ed8b29e07b3023ffbb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc754b5e1e5e4767aefdd2afd123e766": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd9852158e504dfdbc29767e753917dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "e768c7bd58f84d619aeeff042552ee12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecc73a832cba4b23b81f2f669e3fa272": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87c16aafebe74c09bdca2e9ea2f66c36",
              "IPY_MODEL_f5e29e131ecb4ca899c595193b9b3180",
              "IPY_MODEL_1d48c03b2e474ceb9068203b6852022d"
            ],
            "layout": "IPY_MODEL_36519b81805d47f0b35b01b5b1d2a407"
          }
        },
        "f0985bd419d84f648751889b839a75e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5e29e131ecb4ca899c595193b9b3180": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f91a13558a334d3298f574fea7fa5c2c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b2287485eed4ed8b29e07b3023ffbb7",
            "value": 2
          }
        },
        "f7cf2efdc9d348ffbba7804d31b75b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_688fd089cc0647c9aafe64f5422ac0ae",
            "placeholder": "​",
            "style": "IPY_MODEL_6cb5a646ce81417a82557c5ac10b5473",
            "value": " 40/85 [00:20&lt;00:22,  1.98it/s, v_num=ps_0, train_loss_step=0.034, train_acc_step=0.000, train_loss_epoch=0.235, train_acc_epoch=0.000]"
          }
        },
        "f91a13558a334d3298f574fea7fa5c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
